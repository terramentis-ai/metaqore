# MetaQore - Governance-Only AI Infrastructure

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com)

**MetaQore** is a governance-only AI infrastructure platform that enables enterprise AI adoption through "Governance as a Service." It provides mandatory state management, conflict detection, compliance auditing, and security routing for multi-agent systemsâ€”all while handling inference through provider-agnostic LLM integration.

## ğŸš€ Key Features

- **ğŸ”’ Governance-First**: Mandatory PSMP (Project State Management Protocol) enforcement
- **ğŸ¤– Autonomous Specialists**: Self-training AI agents with skill-based routing
- **ğŸ“Š Compliance Ready**: SOC2, GDPR, HIPAA compliance frameworks built-in
- **ğŸ”„ Event-Driven**: Microservices architecture with async event communication
- **âš¡ Production Ready**: Redis caching, Docker orchestration, monitoring
- **ğŸ”Œ Provider Agnostic**: OpenAI, Anthropic, vLLM, Llama.cpp support

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   External      â”‚    â”‚   AI Gateway    â”‚    â”‚  Specialist     â”‚
â”‚   Agents        â”‚â—„â”€â”€â–ºâ”‚   (Routing)     â”‚â—„â”€â”€â–ºâ”‚  Foundry        â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚  (Training)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Compliance      â”‚    â”‚   Event Bus     â”‚    â”‚   AI DevOps     â”‚
â”‚ Auditor         â”‚â—„â”€â”€â–ºâ”‚   (Redis)       â”‚â—„â”€â”€â–ºâ”‚   (Infra)       â”‚
â”‚ (Validation)    â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Services

- **AI Gateway** (Port 8002): Intelligent LLM routing with specialist integration
- **Specialist Foundry** (Port 8001): Autonomous agent training and deployment
- **Compliance Auditor** (Port 8003): Multi-framework compliance validation
- **AI DevOps** (Port 8004): Infrastructure management and GitOps automation

## ğŸ› ï¸ Quick Start

### Prerequisites

- Python 3.11+
- Docker & Docker Compose
- Redis (for production caching)

### Local Development

1. **Clone and setup:**
   ```bash
   git clone <repository>
   cd metaqore
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Start services:**
   ```bash
   docker-compose -f docker-compose.services.yml up -d
   ```

3. **Test the system:**
   ```bash
   curl http://localhost:8002/api/v1/health
   ```

### Production Deployment

1. **Build and deploy:**
   ```bash
   docker-compose -f docker-compose.services.yml -f docker-compose.prod.yml up -d
   ```

2. **Scale services:**
   ```bash
   docker-compose up -d --scale ai-gateway=3
   ```

## ğŸ“š API Documentation

### AI Gateway

**Generate LLM Response:**
```bash
POST /api/v1/llm/generate
Content-Type: application/json

{
  "prompt": "Explain quantum computing",
  "model": "gpt-4",
  "agent_name": "research-assistant",
  "max_tokens": 1000
}
```

**Response:**
```json
{
  "response": "Quantum computing uses quantum mechanics...",
  "model": "gpt-4",
  "processing_time": 1.23,
  "cached": false
}
```

### Specialist Foundry

**Propose Specialist:**
```bash
POST /api/v1/specialists
Content-Type: application/json

{
  "name": "code-reviewer",
  "description": "Reviews code for security issues",
  "skills": ["security", "code-analysis"],
  "training_data": {...}
}
```

### Compliance Auditor

**Run Compliance Check:**
```bash
POST /api/v1/compliance/check
Content-Type: application/json

{
  "framework": "SOC2",
  "scope": {"organization": "default"},
  "evidence_types": ["audit_logs", "data_processing"]
}
```

## ğŸ”§ Configuration

### Environment Variables

| Service | Variable | Default | Description |
|---------|----------|---------|-------------|
| All | `EVENT_BUS_URL` | `redis://localhost:6379` | Event bus connection |
| AI Gateway | `REDIS_CACHE_URL` | `redis://localhost:6379/1` | Cache backend |
| Specialist Foundry | `TRAINING_TIMEOUT` | `3600` | Training timeout (seconds) |
| Compliance Auditor | `AUDIT_RETENTION` | `90` | Audit log retention (days) |

### LLM Providers

Configure provider credentials in environment:

```bash
# OpenAI
OPENAI_API_KEY=sk-...

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# Local vLLM
VLLM_BASE_URL=http://localhost:8000
```

## ğŸ§ª Testing

Run the complete test suite:

```bash
# Unit tests
pytest tests/unit/ -v

# Integration tests
pytest tests/integration/ -v

# Load testing
locust -f tests/load/locustfile.py
```

## ğŸ“Š Monitoring

### Health Checks

All services expose health endpoints:
- `GET /api/v1/health` - Service health status

### Metrics

Prometheus metrics available at `/metrics` on each service.

### Logging

Structured JSON logging with configurable levels:
- `DEBUG`: Detailed debugging information
- `INFO`: General operational messages
- `WARNING`: Warning conditions
- `ERROR`: Error conditions

## ğŸ”’ Security

- **Task Sensitivity Classification**: PUBLIC/INTERNAL/SENSITIVE/CRITICAL
- **Provider Isolation**: Sensitive requests routed to compliant providers
- **Audit Trails**: All actions logged with compliance evidence
- **Access Control**: JWT-based authentication with role-based permissions

## ğŸ“ˆ Performance

### Benchmarks

- **Throughput**: 1000+ RPS with Redis caching
- **Latency**: <100ms for cached responses
- **Concurrent Users**: 10,000+ simultaneous connections

### Scaling

Horizontal scaling supported for all services:
```bash
docker-compose up -d --scale ai-gateway=5
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- FastAPI for the web framework
- Pydantic for data validation
- Redis for caching and event bus
- All the amazing open-source AI community

## ğŸ“ Support

- **Documentation**: [docs/](docs/)
- **Issues**: [GitHub Issues](https://github.com/your-org/metaqore/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-org/metaqore/discussions)

---

**MetaQore** - Enabling enterprise AI adoption with governance you can trust. ğŸš€